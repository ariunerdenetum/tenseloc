{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16709319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73dc94c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x14c027daaa40>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration\n",
    "layers       = [15, 16, 17]\n",
    "streams      = {'residual':'r'}\n",
    "labels       = ['past','present','future']\n",
    "corpora      = ['nontemporal','temporal']\n",
    "output_dir   = './latent_outputs'\n",
    "top_k = 10\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6ee8d2",
   "metadata": {},
   "source": [
    "### Features from cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a44c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features_and_labels(layer, stream, corpora, labels, output_dir):\n",
    "    H_parts, Y = [], []\n",
    "    for corpus in corpora:\n",
    "        for lbl in labels:\n",
    "            p = os.path.join(\n",
    "                output_dir,\n",
    "                f\"{corpus}_{lbl}_l{layer}_{stream}_feature_acts.pt\"\n",
    "            )\n",
    "            # Load tensor once and cast to float32 to avoid BFloat16 numpy conversion error\n",
    "            tensor = torch.load(p).cpu().to(torch.float32)\n",
    "            # Determine reshape dimensions\n",
    "            total_elems = tensor.numel()\n",
    "            batch_size = tensor.shape[0]\n",
    "            feat_dim = total_elems // batch_size\n",
    "            feats = tensor.numpy().reshape(batch_size, feat_dim)\n",
    "\n",
    "            # Load labels\n",
    "            meta_path = p.replace(\"_feature_acts.pt\", \"_metadata.parquet\")\n",
    "            df = pd.read_parquet(meta_path)\n",
    "\n",
    "            H_parts.append(feats)\n",
    "            Y.extend(df['tense'].tolist())\n",
    "    H = np.vstack(H_parts)\n",
    "    return H, np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd404883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 15, stream residual: metrics saved to ./latent_outputs/cosine_features_strength_l15_residual.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 16, stream residual: metrics saved to ./latent_outputs/cosine_features_strength_l16_residual.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 17, stream residual: metrics saved to ./latent_outputs/cosine_features_strength_l17_residual.csv\n"
     ]
    }
   ],
   "source": [
    "# 2 Train one‑vs‑rest probe once per layer/stream\n",
    "\n",
    "le = LabelEncoder().fit(labels)\n",
    "for layer in layers:\n",
    "    records=[]\n",
    "    for target_label in labels:\n",
    "        for corpus in corpora:\n",
    "            for stream in streams:\n",
    "                H, y = load_features_and_labels(layer, stream, corpora, labels, output_dir)\n",
    "                y_int = le.transform(y)\n",
    "                probe = LogisticRegression(multi_class='ovr', solver='liblinear', C=1.0, max_iter=1000)\n",
    "                probe.fit(H, y_int)\n",
    "                coefs = probe.coef_  # shape [3, m]\n",
    "\n",
    "                # compute Cohen's d denominators once\n",
    "                m = H.shape[1]\n",
    "                d_den = {}\n",
    "                for cls_idx, tense in enumerate(le.classes_):\n",
    "                    H_pos = H[y_int==cls_idx]\n",
    "                    H_neg = H[y_int!=cls_idx]\n",
    "                    mu_pos = H_pos.mean(axis=0); mu_neg = H_neg.mean(axis=0)\n",
    "                    sd_pos = H_pos.std(axis=0, ddof=1); sd_neg = H_neg.std(axis=0, ddof=1)\n",
    "                    d_den[tense] = np.sqrt((sd_pos**2+sd_neg**2)/2 + 1e-8)\n",
    "\n",
    "                # 3 Load cosine‑selected top‑k features\n",
    "                idx_path = os.path.join(\n",
    "                    output_dir,\n",
    "                    f\"top_{corpus}_{target_label}_indices_l{layer}_{stream}.pt\"\n",
    "                )\n",
    "                topk = torch.load(idx_path)  # list of indices\n",
    "\n",
    "                # 4 Compute metrics on those features\n",
    "                cls_idx = list(le.classes_).index(target_label)\n",
    "                w_vec = coefs[cls_idx]\n",
    "                mu_pos = H[y_int==cls_idx].mean(axis=0)\n",
    "                mu_neg = H[y_int!=cls_idx].mean(axis=0)\n",
    "                for f in topk:\n",
    "                    records.append({\n",
    "                        'corpus': corpus,\n",
    "                        'label': target_label,\n",
    "                        'layer': layer,\n",
    "                        'stream': stream,\n",
    "                        'feature': f,\n",
    "                        'weight_abs': abs(w_vec[f]),\n",
    "                        'cohen_d_abs': abs((mu_pos[f]-mu_neg[f]) / d_den[target_label][f])\n",
    "                    })\n",
    "\n",
    "    # 5 Save and display\n",
    "    df = pd.DataFrame(records)\n",
    "    csv = os.path.join(\n",
    "        output_dir,\n",
    "        f\"cosine_features_strength_l{layer}_{stream}.csv\"\n",
    "    )\n",
    "    df.to_csv(csv, index=False)\n",
    "    print(f\"Layer {layer}, stream {stream}: metrics saved to {csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a81f47",
   "metadata": {},
   "source": [
    "### Features from probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "113e46a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 15, stream residual: saved to ./latent_outputs/probe_features_strength_l15_residual.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 16, stream residual: saved to ./latent_outputs/probe_features_strength_l16_residual.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/brno2/home/ariuka/tense/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 17, stream residual: saved to ./latent_outputs/probe_features_strength_l17_residual.csv\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder().fit(labels)\n",
    "for layer in layers:\n",
    "    for stream in streams:\n",
    "        H, y = load_features_and_labels(layer, stream, ['nontemporal','temporal'], labels, output_dir)\n",
    "        y_int = le.transform(y)\n",
    "        probe = LogisticRegression(\n",
    "            multi_class='ovr',\n",
    "            solver='liblinear',\n",
    "            C=1.0,\n",
    "            max_iter=1000\n",
    "        )\n",
    "        probe.fit(H, y_int)\n",
    "        W = probe.coef_       # shape [3, m]\n",
    "        m = H.shape[1]\n",
    "\n",
    "        # compute pooled‐sd denominators\n",
    "        d_den = {}\n",
    "        for cls_idx, tense in enumerate(le.classes_):\n",
    "            H_pos = H[y_int==cls_idx]\n",
    "            H_neg = H[y_int!=cls_idx]\n",
    "            sd_pos = H_pos.std(axis=0, ddof=1)\n",
    "            sd_neg = H_neg.std(axis=0, ddof=1)\n",
    "            d_den[tense] = np.sqrt((sd_pos**2 + sd_neg**2)/2 + 1e-8)\n",
    "\n",
    "        records = []\n",
    "        for cls_idx, target in enumerate(le.classes_):\n",
    "            w_vec = W[cls_idx]\n",
    "            # rank features by absolute weight\n",
    "            topk = np.argsort(np.abs(w_vec))[-top_k:]\n",
    "            mu_pos = H[y_int==cls_idx].mean(axis=0)\n",
    "            mu_neg = H[y_int!=cls_idx].mean(axis=0)\n",
    "\n",
    "            for f in topk:\n",
    "                records.append({\n",
    "                    'label'       : target,\n",
    "                    'layer'       : layer,\n",
    "                    'stream'      : stream,\n",
    "                    'feature'     : int(f),\n",
    "                    'weight_abs'  : float(abs(w_vec[f])),\n",
    "                    'cohen_d_abs' : float(abs((mu_pos[f] - mu_neg[f]) / d_den[target][f]))\n",
    "                })\n",
    "\n",
    "        df = pd.DataFrame(records)\n",
    "        out_csv = os.path.join(\n",
    "            output_dir,\n",
    "            f\"probe_features_strength_l{layer}_{stream}.csv\"\n",
    "        )\n",
    "        df.to_csv(out_csv, index=False)\n",
    "        print(f\"Layer {layer}, stream {stream}: saved to {out_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac43f8b",
   "metadata": {},
   "source": [
    "### Getting intersection of cosine and probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71727f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "layers  = [15, 16, 17]\n",
    "streams = ['residual']\n",
    "labels  = ['past', 'present', 'future']\n",
    "output_dir = './latent_outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb2173c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged intersection strengths to ./latent_outputs/chosen_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Collect all intersection records\n",
    "all_records = []\n",
    "\n",
    "for layer in layers:\n",
    "    for stream in streams:\n",
    "        # Paths\n",
    "        path_cos = os.path.join(\n",
    "            output_dir,\n",
    "            f\"cosine_features_strength_l{layer}_{stream}.csv\"\n",
    "        )\n",
    "        path_prb = os.path.join(\n",
    "            output_dir,\n",
    "            f\"probe_features_strength_l{layer}_{stream}.csv\"\n",
    "        )\n",
    "\n",
    "        # Load\n",
    "        df_cos = pd.read_csv(path_cos)\n",
    "        df_prb = pd.read_csv(path_prb)\n",
    "\n",
    "        # Keep only relevant columns\n",
    "        df_cos = df_cos[['label','feature','weight_abs','cohen_d_abs']].copy()\n",
    "        df_prb = df_prb[['label','feature','weight_abs','cohen_d_abs']].copy()\n",
    "\n",
    "        # Rename for clarity\n",
    "        df_cos.rename(columns={\n",
    "            'weight_abs':   'weight_abs_cosine',\n",
    "            'cohen_d_abs':  'cohen_d_abs_cosine'\n",
    "        }, inplace=True)\n",
    "        df_prb.rename(columns={\n",
    "            'weight_abs':   'weight_abs_probe',\n",
    "            'cohen_d_abs':  'cohen_d_abs_probe'\n",
    "        }, inplace=True)\n",
    "\n",
    "        # Merge on label & feature\n",
    "        df_merged = pd.merge(\n",
    "            df_cos,\n",
    "            df_prb,\n",
    "            on=['label','feature'],\n",
    "            how='inner'\n",
    "        )\n",
    "\n",
    "        # Annotate layer & stream\n",
    "        df_merged['layer']  = layer\n",
    "        df_merged['stream'] = stream\n",
    "\n",
    "        # Collect\n",
    "        all_records.append(df_merged)\n",
    "\n",
    "# Concatenate all and save\n",
    "df_all = pd.concat(all_records, ignore_index=True)\n",
    "out_path = os.path.join(output_dir, \"chosen_features.csv\")\n",
    "df_all.to_csv(out_path, index=False)\n",
    "print(f\"Saved merged intersection strengths to {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd115b6b",
   "metadata": {},
   "source": [
    "- weight_abs\n",
    "\n",
    "    - Magnitude of logistic‐regression coefficient.\n",
    "\n",
    "    - No absolute “unit” – depends on feature scaling.\n",
    "\n",
    "    - In your layer 15 data it spans roughly 0.00.0 to ∼2.2∼2.2.\n",
    "\n",
    "    - Use relative ranking: features with ∣wi∣>1∣wi​∣>1 are strong contributors; <0.5<0.5 are weak.\n",
    "\n",
    "- cohen_d_abs\n",
    "\n",
    "    - Standardized effect‐size:\n",
    "\n",
    "        - 0.20.2 = small\n",
    "\n",
    "        - 0.50.5 = medium\n",
    "\n",
    "        - 0.80.8 = large\n",
    "\n",
    "        - >1.3>1.3 = very large\n",
    "\n",
    "    - Features with d>0.8d>0.8 are reliably discriminative; d<0.5d<0.5 borderline.\n",
    "\n",
    "- Conclusion\n",
    "\n",
    "    - Aim for features with both ∣wi∣>1∣wi∣>1 and di>0.8di>0.8.\n",
    "\n",
    "    - Lower values signal weak or noisy signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c1be66",
   "metadata": {},
   "source": [
    "- Visualize using table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73301b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tense_venv)",
   "language": "python",
   "name": "tense_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
